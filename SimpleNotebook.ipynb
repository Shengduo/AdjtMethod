{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import standard librarys\n",
    "import torch\n",
    "import torchdiffeq\n",
    "import pickle\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import scipy.optimize as opt\n",
    "import numpy as np\n",
    "\n",
    "from torchdiffeq import odeint\n",
    "from xitorch.interpolate import Interp1D\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "## Import local classes and functions\n",
    "from MassFricParams import MassFricParams\n",
    "from TimeSequenceGen import TimeSequenceGen\n",
    "from AdjointMethod import AdjDerivs\n",
    "from GradientDescent import GradDescent, objGradFunc\n",
    "\n",
    "torch.set_default_dtype(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(69.7707)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(1.e30)\n",
    "torch.asinh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(69.7707)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(2. * a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate steady state friction coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_targ = torch.tensor([0.011, 0.016, 0.1, 0.58])\n",
    "beta = torch.tensor([ 0.0111, -0.0027,  0.1000,  0.2810])\n",
    "V = torch.tensor([1., 10., 100.])\n",
    "\n",
    "# Calculate stead state\n",
    "def calFSS(beta, V):\n",
    "    res = beta[3] + (beta[0] - beta[1]) * torch.log(V / 1.e-6)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4, 12, 32],\n",
       "        [ 2,  8, 18, 20]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4,])\n",
    "b = torch.tensor([[1, 2, 4, 8], [2, 4, 6, 5]])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(V.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate memory\n",
    "res = torch.zeros(len(tts), 2, self.kwgs['NofTpts'])\n",
    "for idx, (tt, VV) in enumerate(zip(tts, VVs)):\n",
    "    T = torch.linspace(tt[0], tt[-1], self.kwgs['NofTpts'])\n",
    "    InterpFunc = interp1d(tt, VV)\n",
    "    V = torch.tensor(InterpFunc(T), dtype = torch.float)\n",
    "    res[idx, 1, :] = V\n",
    "    res[idx, 0, :] = T\n",
    "    \n",
    "# Update self.tt, self.VV\n",
    "self.tts = tts\n",
    "self.VVs = VVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5109, 0.4994, 0.4879])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calFSS(beta_targ, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4717, 0.5034, 0.5352])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calFSS(beta, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent on fixed $\\alpha = [k, m, g]$ and $V$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters\n",
    "alpha0 = torch.tensor([50., 1., 9.8])\n",
    "VT = torch.tensor([[1., 1.], [0., 5.]])\n",
    "\n",
    "# Alpha range\n",
    "alp_low = torch.tensor([50., 0.5, 1., 9.])\n",
    "alp_hi = torch.tensor([100., 2., 10., 10.])\n",
    "y0 = torch.tensor([0., 1.0, 1.0])\n",
    "\n",
    "# Start beta\n",
    "beta0 = torch.tensor([0.008, 0.012, 2.e0, 0.5])\n",
    "\n",
    "# Target beta\n",
    "beta_targ = torch.tensor([0.011, 0.016, 1.e0, 0.58])\n",
    "\n",
    "# Beta ranges\n",
    "beta_low = torch.tensor([0.001, 0.006, 0.5e-3, 0.3])\n",
    "beta_high = torch.tensor([0.021, 0.026, 5, 0.8])\n",
    "scaling = torch.tensor([1., 1., 1., 1.])\n",
    "\n",
    "# Other arguments for optAlpha function\n",
    "max_iters = 100\n",
    "maxFuncCalls = 200\n",
    "regularizedFlag = False\n",
    "noLocalSearch = True\n",
    "\n",
    "# Sequence specific parameters\n",
    "T = 5.\n",
    "NofTPts = 1000\n",
    "\n",
    "# Tolerance parameters\n",
    "this_rtol = 1.e-6\n",
    "this_atol = 1.e-8\n",
    "\n",
    "# Store the keywords for optAlpha\n",
    "kwgs = {\n",
    "    'y0' : y0, \n",
    "    'alpha0' : alpha0, \n",
    "    'VT' : VT,\n",
    "    'alp_low' : alp_low, \n",
    "    'alp_high' : alp_hi, \n",
    "    'max_iters' : max_iters, \n",
    "    'beta_this' : beta0, \n",
    "    'beta_targ' : beta_targ, \n",
    "    'beta_low' : beta_low, \n",
    "    'beta_high' : beta_high, \n",
    "    'regularizedFlag' : regularizedFlag, \n",
    "    'maxFuncCalls' : maxFuncCalls, \n",
    "    'noLocalSearch' : noLocalSearch, \n",
    "    'T' : T, \n",
    "    'NofTPts' : NofTPts, \n",
    "    'this_rtol': this_rtol, \n",
    "    'this_atol' : this_atol\n",
    "}\n",
    "\n",
    "# Function to get target v\n",
    "def generate_target_v(alpha, VT, beta, y0, this_rtol, this_atol, regularizedFlag):\n",
    "    # y0[1] = alpha[2]\n",
    "    targ_SpringSlider = MassFricParams(alpha, VT, beta, y0)\n",
    "    targ_SpringSlider.print_info()\n",
    "    targ_seq = TimeSequenceGen(T, NofTPts, targ_SpringSlider, \n",
    "                               rtol=this_rtol, atol=this_atol, regularizedFlag=regularizedFlag)\n",
    "    v = targ_seq.default_y[1, :], \n",
    "    t = targ_seq.t\n",
    "    return v[0], t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################  Total Iteration 0 ########################################\n",
      "--------------------  Mass and spring parameters  --------------------\n",
      "k:         tensor(50.)\n",
      "m:         tensor(1.)\n",
      "g:         tensor(9.8000)\n",
      "\n",
      "\n",
      "--------------------  Rate-and-state parameters  --------------------\n",
      "fr:        tensor(0.5800)\n",
      "a:         tensor(0.0110)\n",
      "b:         tensor(0.0160)\n",
      "DRS:       tensor(1.)\n",
      "y0:        tensor([0., 1., 1.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shengduo/InverseProblems/AdjtMethod/MassFricParams.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(s, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost in computing gradients:  0.45262575149536133\n",
      "shit\n",
      "Time cost in computing gradients:  0.44380927085876465\n",
      "========================================\n",
      "Initial descent succeeds:  tensor(True)\n",
      "Observation:  tensor(0.0038)\n",
      "Gradient (scaled):  tensor([-1.9977e+00,  3.2467e+00,  1.2518e-03, -2.2420e-01])\n",
      "Relative error of observation:  tensor(0.0019)\n",
      "Time cost in computing gradients:  0.36985158920288086\n",
      "========================================\n",
      "The 1th descent succeeds:  tensor(True)\n",
      "Gradient (scaled):  tensor([-2.7512e-01,  2.5257e-01,  8.6851e-05, -1.7562e-02])\n",
      "Relative error of observation:  tensor(0.0003)\n",
      "Time cost in computing gradients:  0.3769958019256592\n",
      "========================================\n",
      "The 2th descent succeeds:  tensor(True)\n",
      "Gradient (scaled):  tensor([-1.1474e-01, -3.5268e-02, -8.1763e-06,  2.3028e-03])\n",
      "Relative error of observation:  tensor(0.0003)\n",
      "Time cost in computing gradients:  0.3844032287597656\n",
      "========================================\n",
      "The 3th descent succeeds:  tensor(True)\n",
      "Gradient (scaled):  tensor([-9.9088e-02, -5.2304e-02, -1.3675e-05,  3.4806e-03])\n",
      "Relative error of observation:  tensor(0.0003)\n",
      "Time cost in computing gradients:  0.387066125869751\n",
      "========================================\n",
      "The 4th descent succeeds:  tensor(True)\n",
      "Gradient (scaled):  tensor([-8.8147e-02, -4.6604e-02, -1.1708e-05,  3.0920e-03])\n",
      "Relative error of observation:  tensor(0.0002)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=23'>24</a>\u001b[0m \u001b[39m# Run gradient descent\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=24'>25</a>\u001b[0m myGradBB \u001b[39m=\u001b[39m GradDescent(this_alpha, kwgs[\u001b[39m'\u001b[39m\u001b[39malp_low\u001b[39m\u001b[39m'\u001b[39m], kwgs[\u001b[39m'\u001b[39m\u001b[39malp_high\u001b[39m\u001b[39m'\u001b[39m], kwgs[\u001b[39m'\u001b[39m\u001b[39mVT\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=25'>26</a>\u001b[0m                        this_beta, kwgs[\u001b[39m'\u001b[39m\u001b[39mbeta_low\u001b[39m\u001b[39m'\u001b[39m], kwgs[\u001b[39m'\u001b[39m\u001b[39mbeta_high\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=26'>27</a>\u001b[0m                        kwgs[\u001b[39m'\u001b[39m\u001b[39my0\u001b[39m\u001b[39m'\u001b[39m], v, t, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=29'>30</a>\u001b[0m                        regularizedFlag \u001b[39m=\u001b[39m kwgs[\u001b[39m'\u001b[39m\u001b[39mregularizedFlag\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=30'>31</a>\u001b[0m                        T \u001b[39m=\u001b[39m kwgs[\u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m], NofTPts \u001b[39m=\u001b[39m kwgs[\u001b[39m'\u001b[39m\u001b[39mNofTPts\u001b[39m\u001b[39m'\u001b[39m], this_rtol \u001b[39m=\u001b[39m kwgs[\u001b[39m'\u001b[39m\u001b[39mthis_rtol\u001b[39m\u001b[39m'\u001b[39m], this_atol \u001b[39m=\u001b[39m kwgs[\u001b[39m'\u001b[39m\u001b[39mthis_atol\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=32'>33</a>\u001b[0m myGradBB\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=34'>35</a>\u001b[0m \u001b[39m# Update parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shengduo/InverseProblems/AdjtMethod/SimpleNotebook.ipynb#ch0000005?line=35'>36</a>\u001b[0m this_beta \u001b[39m=\u001b[39m myGradBB\u001b[39m.\u001b[39mbeta_optimal\n",
      "File \u001b[0;32m~/InverseProblems/AdjtMethod/GradientDescent.py:192\u001b[0m, in \u001b[0;36mGradDescent.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=189'>190</a>\u001b[0m \u001b[39m# Run max_iters number of iterations\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=190'>191</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps):\n\u001b[0;32m--> <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=191'>192</a>\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moneDescent()\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=192'>193</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m40\u001b[39m)\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=193'>194</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39mth descent succeeds: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), success)\n",
      "File \u001b[0;32m~/InverseProblems/AdjtMethod/GradientDescent.py:160\u001b[0m, in \u001b[0;36mGradDescent.oneDescent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=156'>157</a>\u001b[0m beta_trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbetas[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m stepSize \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrads[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=158'>159</a>\u001b[0m \u001b[39m# Append the betas and objs\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=159'>160</a>\u001b[0m obj_trial, grad_trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjGrad_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha0, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mVT, beta_trial, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my0, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarg_y, \n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=160'>161</a>\u001b[0m                                           \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaling, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregularizedFlag, \u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=161'>162</a>\u001b[0m                                           \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mNofTPts, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthis_rtol, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthis_atol)\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=162'>163</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbetas\u001b[39m.\u001b[39mappend(beta_trial)\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=163'>164</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjs\u001b[39m.\u001b[39mappend(obj_trial)\n",
      "File \u001b[0;32m~/InverseProblems/AdjtMethod/GradientDescent.py:55\u001b[0m, in \u001b[0;36mobjGradFunc\u001b[0;34m(alpha, VT, beta, y0, targ_y, scaling, regularizedFlag, objOnly, T, NofTPts, this_rtol, this_atol)\u001b[0m\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=52'>53</a>\u001b[0m     grad \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=53'>54</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=54'>55</a>\u001b[0m     myAdj \u001b[39m=\u001b[39m AdjDerivs(this_seq\u001b[39m.\u001b[39;49mdefault_y, targ_y, this_seq\u001b[39m.\u001b[39;49mt, this_SpringSlider, \n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=55'>56</a>\u001b[0m                       rtol \u001b[39m=\u001b[39;49m this_rtol, atol \u001b[39m=\u001b[39;49m this_atol, regularizedFlag \u001b[39m=\u001b[39;49m regularizedFlag)\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=56'>57</a>\u001b[0m     grad \u001b[39m=\u001b[39m myAdj\u001b[39m.\u001b[39mdOdBeta \u001b[39m/\u001b[39m scaling\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/GradientDescent.py?line=58'>59</a>\u001b[0m \u001b[39mreturn\u001b[39;00m obj, grad\n",
      "File \u001b[0;32m~/InverseProblems/AdjtMethod/AdjointMethod.py:61\u001b[0m, in \u001b[0;36mAdjDerivs.__init__\u001b[0;34m(self, y, v, t, MFParams, regularizedFlag, rtol, atol)\u001b[0m\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=58'>59</a>\u001b[0m \u001b[39m# Calculate dOdBeta\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=59'>60</a>\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=60'>61</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdOdBeta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDODBeta()\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=61'>62</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_cost \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m st\n\u001b[1;32m     <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTime cost in computing gradients: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_cost)\n",
      "File \u001b[0;32m~/InverseProblems/AdjtMethod/AdjointMethod.py:188\u001b[0m, in \u001b[0;36mAdjDerivs.DODBeta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=184'>185</a>\u001b[0m L0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=186'>187</a>\u001b[0m \u001b[39m# Solve for L(t)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=187'>188</a>\u001b[0m L \u001b[39m=\u001b[39m odeint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf_l, L0, torch\u001b[39m.\u001b[39;49mflip(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtau, [\u001b[39m0\u001b[39;49m]), \n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=188'>189</a>\u001b[0m            rtol \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrtol, atol \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matol, method \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mdopri5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=190'>191</a>\u001b[0m L \u001b[39m=\u001b[39m L\u001b[39m.\u001b[39mreshape([L\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, L\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]])\n\u001b[1;32m    <a href='file:///home/shengduo/InverseProblems/AdjtMethod/AdjointMethod.py?line=191'>192</a>\u001b[0m L \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(L, [\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py?line=73'>74</a>\u001b[0m solver \u001b[39m=\u001b[39m SOLVERS[method](func\u001b[39m=\u001b[39mfunc, y0\u001b[39m=\u001b[39my0, rtol\u001b[39m=\u001b[39mrtol, atol\u001b[39m=\u001b[39matol, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py?line=75'>76</a>\u001b[0m \u001b[39mif\u001b[39;00m event_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py?line=76'>77</a>\u001b[0m     solution \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39;49mintegrate(t)\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py?line=77'>78</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py?line=78'>79</a>\u001b[0m     event_t, solution \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39mintegrate_until_event(t[\u001b[39m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py?line=27'>28</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(t)):\n\u001b[0;32m---> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py?line=29'>30</a>\u001b[0m     solution[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_advance(t[i])\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=191'>192</a>\u001b[0m \u001b[39mwhile\u001b[39;00m next_t \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrk_state\u001b[39m.\u001b[39mt1:\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=192'>193</a>\u001b[0m     \u001b[39massert\u001b[39;00m n_steps \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_num_steps, \u001b[39m'\u001b[39m\u001b[39mmax_num_steps exceeded (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m>=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(n_steps, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=193'>194</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrk_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adaptive_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrk_state)\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=194'>195</a>\u001b[0m     n_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=195'>196</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _interp_evaluate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrk_state\u001b[39m.\u001b[39minterp_coeff, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrk_state\u001b[39m.\u001b[39mt0, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrk_state\u001b[39m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=249'>250</a>\u001b[0m         dt \u001b[39m=\u001b[39m t1 \u001b[39m-\u001b[39m t0\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=251'>252</a>\u001b[0m \u001b[39m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=252'>253</a>\u001b[0m \u001b[39m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=254'>255</a>\u001b[0m y1, f1, y1_error, k \u001b[39m=\u001b[39m _runge_kutta_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, y0, f0, t0, dt, t1, tableau\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtableau)\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=255'>256</a>\u001b[0m \u001b[39m# dtypes:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=256'>257</a>\u001b[0m \u001b[39m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=257'>258</a>\u001b[0m \u001b[39m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=262'>263</a>\u001b[0m \u001b[39m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=263'>264</a>\u001b[0m \u001b[39m########################################################\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=264'>265</a>\u001b[0m error_ratio \u001b[39m=\u001b[39m _compute_error_ratio(y1_error, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrtol, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matol, y0, y1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:76\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=73'>74</a>\u001b[0m         perturb \u001b[39m=\u001b[39m Perturb\u001b[39m.\u001b[39mNONE\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=74'>75</a>\u001b[0m     yi \u001b[39m=\u001b[39m y0 \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msum(k[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m (beta_i \u001b[39m*\u001b[39m dt), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mview_as(f0)\n\u001b[0;32m---> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=75'>76</a>\u001b[0m     f \u001b[39m=\u001b[39m func(ti, yi, perturb\u001b[39m=\u001b[39;49mperturb)\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=76'>77</a>\u001b[0m     k \u001b[39m=\u001b[39m _UncheckedAssign\u001b[39m.\u001b[39mapply(k, f, (\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=78'>79</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (tableau\u001b[39m.\u001b[39mc_sol[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m (tableau\u001b[39m.\u001b[39mc_sol[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m tableau\u001b[39m.\u001b[39mbeta[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mall()):\n\u001b[1;32m     <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py?line=79'>80</a>\u001b[0m     \u001b[39m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1125'>1126</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1126'>1127</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1127'>1128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1128'>1129</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1130'>1131</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1131'>1132</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:179\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=174'>175</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(perturb, Perturb), \u001b[39m\"\u001b[39m\u001b[39mperturb argument must be of type Perturb enum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=175'>176</a>\u001b[0m \u001b[39m# This dtype change here might be buggy.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=176'>177</a>\u001b[0m \u001b[39m# The exact time value should be determined inside the solver,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=177'>178</a>\u001b[0m \u001b[39m# but this can slightly change it due to numerical differences during casting.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=178'>179</a>\u001b[0m t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mto(y\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=179'>180</a>\u001b[0m \u001b[39mif\u001b[39;00m perturb \u001b[39mis\u001b[39;00m Perturb\u001b[39m.\u001b[39mNEXT:\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=180'>181</a>\u001b[0m     \u001b[39m# Replace with next smallest representable value.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/shengduo/anaconda3/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py?line=181'>182</a>\u001b[0m     t \u001b[39m=\u001b[39m _nextafter(t, t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Number of total alpha-beta iterations\n",
    "N_AllIters = 1\n",
    "this_alpha = alpha0\n",
    "this_beta = beta0\n",
    "\n",
    "## Run alpha-beta iterations\n",
    "for i in range(N_AllIters):\n",
    "    # Print out info\n",
    "    print(\"#\" * 40, \" Total Iteration {0} \".format(i) + \"#\" * 40)\n",
    "    \n",
    "    ## First optimize alpha\n",
    "    kwgs['alpha0'] = this_alpha\n",
    "    kwgs['beta_this'] = this_beta\n",
    "    \n",
    "    # Timing alpha\n",
    "    # Update this Alpha\n",
    "    # this_alpha = optAlpha(O_GAN, kwgs)\n",
    "    \n",
    "    \n",
    "    ## Run grad descent on beta\n",
    "    # Generate target v\n",
    "    v, t = generate_target_v(this_alpha, kwgs['VT'], kwgs['beta_targ'], kwgs['y0'], kwgs['this_rtol'], kwgs['this_atol'], kwgs['regularizedFlag'])\n",
    "    \n",
    "    # Run gradient descent\n",
    "    myGradBB = GradDescent(this_alpha, kwgs['alp_low'], kwgs['alp_high'], kwgs['VT'], \n",
    "                           this_beta, kwgs['beta_low'], kwgs['beta_high'], \n",
    "                           kwgs['y0'], v, t, \n",
    "                           objGrad_func = objGradFunc, scaling = scaling, \n",
    "                           max_steps = 10, stepping = 'BB', obs_rtol = 1e-5, lsrh_steps = 10, \n",
    "                           regularizedFlag = kwgs['regularizedFlag'], \n",
    "                           T = kwgs['T'], NofTPts = kwgs['NofTPts'], this_rtol = kwgs['this_rtol'], this_atol = kwgs['this_atol'])\n",
    "    \n",
    "    myGradBB.run()\n",
    "    \n",
    "    # Update parameters\n",
    "    this_beta = myGradBB.beta_optimal\n",
    "    print(\"Optimal beta: \", this_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
